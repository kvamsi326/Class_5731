{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second In-class-exercise (09/22/2022, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "\n",
    ". The research question I have to analyse is the prices of Boys costumes available in eBay which is an e-commerce website.\n",
    ". For this, I have to collect the prices of the costumes that are visible to users from website by filtering the results \n",
    "using Boys costumes.\n",
    ". There are 91, 862 results for the search Boys costumes.\n",
    ". We can collect the data and then plot to analyse the price range and high price, low price as analysis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import json\n",
    "import re\n",
    "total_count = 0\n",
    "count = 0\n",
    "\n",
    "prices = {\"Price\": []}\n",
    "main_url = \"https://www.ebay.com/b/Boys-Costumes/80913/bn_862624?_pgn={}\"\n",
    "for page_num in range(1, 10):\n",
    "\n",
    "    link1 = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    url1 = urlopen(link1)\n",
    "\n",
    "    data1 = url1.read()\n",
    "    data1_soup = BeautifulSoup(data1)\n",
    "    for price in data1_soup.find_all(\"span\", attrs={'class':'s-item__price'}):\n",
    "        prices['Price'].append(price.text.replace(\"\\t\", \"\"))\n",
    "        \n",
    "df = pd.DataFrame(prices)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "                                               Title  \\\n",
      "0                              Information Retrieval   \n",
      "1                       Modern Information Retrieval   \n",
      "2                      Private Information Retrieval   \n",
      "3           An Introduction to Information Retrieval   \n",
      "4  Naive (Bayes) at Forty: The Independence Assum...   \n",
      "\n",
      "                                   Authors  Year  \\\n",
      "0                        C.J.vanRijsbergen  1979   \n",
      "1  RicardoBaeza-Yates,BerthierRibeiro-Neto  1999   \n",
      "2                          BennyChor,etal.     0   \n",
      "3               ChristopherD.Manning,etal.  2007   \n",
      "4                             DavidD.Lewis  1998   \n",
      "\n",
      "                                            Abstract  \n",
      "0                                        \"...   ...\"  \n",
      "1  \"... Information retrieval (IR) has changed co...  \n",
      "2  \"...   We describe schemes that enable a user ...  \n",
      "3                                        \"...   ...\"  \n",
      "4  \"... The naive Bayes classifier, currently exp...  \n",
      "(500, 4)\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "    \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import json\n",
    "import re\n",
    "total_count = 0\n",
    "count = 0\n",
    "\n",
    "result_df = {\"Title\":[], \"Authors\":[], \"Year\":[], \"Abstract\":[]}\n",
    "main_url = \"https://citeseerx.ist.psu.edu/search?q=information+retrieval&t=doc&sort=rlv&start={}\"\n",
    "for page_num in range(0, 5000, 10):\n",
    "    #print(main_url.format(page_num))\n",
    "    link1 = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    url1 = urlopen(link1)\n",
    "\n",
    "    data1 = url1.read()\n",
    "    data1_soup = BeautifulSoup(data1)\n",
    "    #print(data1_soup)\n",
    "    \n",
    "    for i in data1_soup.find_all(\"a\", attrs={'class':'remove doc_details'}):\n",
    "        #print(i.text.strip())\n",
    "        result_df[\"Title\"].append(i.text.strip())\n",
    "        \n",
    "    for i in data1_soup.find_all(\"div\", attrs={'class':'pubinfo'}):\n",
    "        #print(len(i.find_all(\"span\")))\n",
    "        if len(i.find_all(\"span\")) < 2:\n",
    "            result_df[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_df['Year'].append(0)\n",
    "\n",
    "        elif len(i.find_all(\"span\")) > 2:\n",
    "            result_df[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_df['Year'].append(i.find_all(\"span\")[2].text.split()[1])\n",
    "        \n",
    "        else:\n",
    "            result_df[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_df['Year'].append(i.find_all(\"span\")[1].text.split()[1])\n",
    "    for i in data1_soup.find_all(\"div\", attrs={'class':'snippet'}):\n",
    "        #for j in i.find_all(\"span\"):\n",
    "        #print(i.text.replace(\" \", \"\"))\n",
    "        #print(i.text)\n",
    "        result_df[\"Abstract\"].append(i.text)\n",
    "    #print(title)\n",
    "    \n",
    "print(len(result_df[\"Title\"]))\n",
    "print(len(result_df[\"Authors\"]))\n",
    "print(len(result_df[\"Year\"]))\n",
    "print(len(result_df[\"Abstract\"]))\n",
    "df = pd.DataFrame(result_df)\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "#df['Year'] = df['Year'].astype(\"int\")\n",
    "#df[df['Year'] >= 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @polo_kimani: Brudda,usiwahi dhania hawa chiles wa Twitter for iphone wako out of your league,( financially they are) but the iphone huwâ€¦\n",
      "2022-09-25 15:16:34+00:00\n",
      "\n",
      "@thismikael @KnobSlobberz @CaliMOfficial_ @ATLONIKA How she aggressively throwing that big burnt brownie on my iPhoâ€¦ https://t.co/LjLmQHfXT8\n",
      "2022-09-25 15:16:30+00:00\n",
      "\n",
      "RT @nftbadger: When you drop your friendâ€™s new iphone https://t.co/aZvg2VcdV8\n",
      "2022-09-25 15:16:29+00:00\n",
      "\n",
      "RT @nftbadger: When you drop your friendâ€™s new iphone https://t.co/aZvg2VcdV8\n",
      "2022-09-25 15:16:29+00:00\n",
      "\n",
      "RT @nftbadger: When you drop your friendâ€™s new iphone https://t.co/aZvg2VcdV8\n",
      "2022-09-25 15:16:26+00:00\n",
      "\n",
      "RT @alhajinuell: I never see affiliate marketer wey buy iPhone 14. I thought yâ€™all were making over 200k everyday while we were sleeping? ðŸ˜‚â€¦\n",
      "2022-09-25 15:16:26+00:00\n",
      "\n",
      "I'm using #Watusi on iPhone by @FouadRaheb to add new features for #WhatsApp! https://t.co/aRK1rm8WFC\n",
      "2022-09-25 15:16:24+00:00\n",
      "\n",
      "RT @nftbadger: When you drop your friendâ€™s new iphone https://t.co/aZvg2VcdV8\n",
      "2022-09-25 15:16:24+00:00\n",
      "\n",
      "Lung cancer to the right of B3 Skid and pup's Step sister 8: The twitter bot For iPhone: Beta version\n",
      "2022-09-25 15:16:24+00:00\n",
      "\n",
      "Thanks goes out to @TwitterSupport for fixing the #Twitter #iPhone app, \"Tweet Activity\" capability\n",
      "2022-09-25 15:16:21+00:00\n",
      "\n",
      "RT @OGBdeyforyou: @blacksherif_ @Mbahdeyforyou Them don promise your babe iPhone 14?\n",
      "2022-09-25 15:16:20+00:00\n",
      "\n",
      "Had a feeling the iPhone 14 Pro Max would win this.\n",
      "\n",
      "Only problem is the Pixel 6 Pro takes the best still images ðŸ¤”\n",
      "2022-09-25 15:16:19+00:00\n",
      "\n",
      "RT @appleinsider: The 2023 fall updates to the #iPhone lineup could introduce a new iPhone 15 Ultra model, replacing the usual Pro Max variâ€¦\n",
      "2022-09-25 15:16:18+00:00\n",
      "\n",
      "iPhone users - how much proprietary intelligence is in a Lightning charge cable? Have recently had both a genuine câ€¦ https://t.co/agXaLJd7Uu\n",
      "2022-09-25 15:16:18+00:00\n",
      "\n",
      "RT @mhauken: 9 iPhone apps that can double your productivity:\n",
      "2022-09-25 15:16:16+00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "key= '2Em7SxlX9jPMfL4x97r3zMO0x'\n",
    "secret= 'sVbJzekKuiAgq83Y7gCwNVbSowqQokGVzWexKHl2cXIPceWtSd'\n",
    "token= '1439767876962029572-uUMt8oWRyzj9ilE5zk4uYbL93sCMPT'\n",
    "access= 'oydIGymn9bS767FVEMawE9GyGAnMmBJfaY2XXKmHnmliF'\n",
    "\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(key, secret)\n",
    "\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(token, access)\n",
    "\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "for tweets in api.search_tweets(q=\"iphone\", lang=\"en\"):\n",
    "    print(tweets.text)\n",
    "    print(tweets.created_at)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
